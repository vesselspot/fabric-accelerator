{
  "queryset": {
    "version": "1.0.0",
    "dataSources": [
      {
        "id": "4133f2a7-9b55-4846-89fa-b41381ea1e5d",
        "clusterUri": "",
        "type": "Fabric",
        "databaseItemId": "b11fae50-0ed3-409c-881e-511fea943461",
        "databaseItemName": "kdb_fabricEvents"
      }
    ],
    "tabs": [
      {
        "id": "9e6e1619-d0c3-4827-bc1f-34cc9440777e",
        "content": "jobEventsExpanded\n| where jobStatus == 'Completed' and jobEndTimeUtc >= ago(45d)\n| extend jobDurationSeconds = jobDurationSeconds\n| project jobEndTimeUtc, itemName, jobType, jobDurationSeconds\n| sort by jobEndTimeUtc desc\n\n\njobEventsExpanded\n| where jobStatus == 'Completed' and jobEndTimeUtc >= ago(45d)\n| extend jobDurationMin = jobDurationSeconds / 60\n| project jobEndTimeUtc, itemName, jobType, jobDurationMin\n| sort by jobEndTimeUtc desc\n\njobEventsExpanded\n| where jobEndTimeUtc >= ago(90d)\n| extend executionDurationMins = jobDurationSeconds / 60\n| summarize avgExecutionDurationMins=avg(executionDurationMins) by bin(jobEndTimeUtc, 1d), itemName\n| project jobEndTimeUtc, itemName, avgExecutionDurationMins\n| order by jobEndTimeUtc asc\n| render timechart\n\n\n\njobEventsExpanded\n| where jobEndTimeUtc >= ago(30d)\n| extend executionDurationMins = jobDurationSeconds / 60\n| summarize avgExecutionDurationMins=avg(executionDurationMins) by bin(jobEndTimeUtc, 1d), itemName\n| render timechart\n\n// Useful troubleshooting queries\n.show operations ('88d7c22c-63ed-431f-874c-24cc9d74ac23');\n\n.show table * policy  update\n\n.show ingestion failures ;\n\nlet _startTime = now()-10d;\nlet _endTime = now();\nlet span = 1d;\nmaterialized_view(\"dailyAggJobEvents\")\n| where [\"time\"] between (_startTime .._endTime ) and isnotempty(itemName)\n// | where itemName in (_itemName) or   isempty( _itemName)\n| extend jobDurationMin = datetime_diff('minute',jobEndTimeUtc,jobStartTimeUtc)\n| make-series tsDurationMin = avg(jobDurationMin) default=int(null) on [\"time\"] from _startTime to _endTime step span by itemName\n| extend tsDurationMin = series_fill_linear(tsDurationMin) //fill missing null values with linear interpolation\n| extend (anamolies, score,baseline) = series_decompose_anomalies(tsDurationMin,1.5,-1,\"linefit\")\n| project itemName,tsDurationMin, anamolies,[\"time\"]\n\n\n// let minTs = toscalar (materialized_view(\"dailyAggJobEvents\")|summarize  min([\"time\"]));\n// let maxTs = toscalar (materialized_view(\"dailyAggJobEvents\")|summarize  max([\"time\"]));\n// materialized_view(\"dailyAggJobEvents\")\n// // |where [\"time\"] between (_startTime .._endTime )\n// | extend jobDurationMin = datetime_diff('minute',jobEndTimeUtc,jobStartTimeUtc)\n// | make-series avgJobDurationMin = avg(jobDurationMin) default=0 on [\"time\"] from minTs to maxTs step 1d by itemName\n// | extend maAvgJobDurationMin = series_fir(avgJobDurationMin, repeat(1,5),true, true)\n// | extend residual = series_subtract(avgJobDurationMin, maAvgJobDurationMin)\n// | render timechart \n\n// //Test Highwatermark\n// let hwm = toscalar(jobEventsExpanded|summarize hwm= iff(isnull(max([\"time\"])),ago(30d), max([\"time\"])));\n// jobEvents\n// |where [\"time\"] > hwm\n// |extend jd = parse_json(data)\n// |extend itemId = tostring(jd.itemId),\n//         itemName = tostring(jd.itemName),\n//         workspaceId = tostring(jd.workspaceId),\n//         workspaceName = tostring(jd.workspaceName),\n//         itemKind = tostring(jd.itemKind),\n//         executingPrincipalId = tostring(jd.executingPrincipalId),\n//         executingPrincipalType = tostring(jd.executingPrincipalType),\n//         jobInstanceId = tostring(jd.jobInstanceId),\n//         jobType = tostring(jd.jobType),\n//         jobInvokeType = tostring(jd.jobInvokeType),\n//         jobStatus = tostring(jd.jobStatus),\n//         jobStartTimeUtc = todatetime(jd.jobStartTimeUtc),\n//         jobEndTimeUtc = todatetime(jd.jobEndTimeUtc),\n//         jobScheduleTimeUtc = todatetime(jd.jobScheduleTimeUtc),\n//         jobDefinitionObjectId = todatetime(jd.jobDefinitionObjectId)\n// |project-away jd,data\n// |order by [\"time\"] desc;\n\nstorageEventsExpanded\n| summarize count() by source",
        "title": "Queries",
        "dataSourceId": "4133f2a7-9b55-4846-89fa-b41381ea1e5d"
      },
      {
        "id": "caf9a056-bb18-4211-b561-a8e0f9618e41",
        "content": ".execute  database script <|\n    .create-or-alter function with (docstring ='Function called on JobEvents update policy to flatten/expand JSON data') \n    expandJobEvents() \n    {\n        jobEvents\n        |extend jd = parse_json(data)\n        |extend itemId = tostring(jd.itemId),\n                itemName = tostring(jd.itemName),\n                workspaceId = tostring(jd.workspaceId),\n                workspaceName = tostring(jd.workspaceName),\n                itemKind = tostring(jd.itemKind),\n                executingPrincipalId = tostring(jd.executingPrincipalId),\n                executingPrincipalType = tostring(jd.executingPrincipalType),\n                jobInstanceId = tostring(jd.jobInstanceId),\n                jobType = tostring(jd.jobType),\n                jobInvokeType = tostring(jd.jobInvokeType),\n                jobStatus = tostring(jd.jobStatus),\n                jobStartTimeUtc = todatetime(jd.jobStartTimeUtc),\n                jobEndTimeUtc = todatetime(jd.jobEndTimeUtc),\n                jobScheduleTimeUtc = todatetime(jd.jobScheduleTimeUtc),\n                jobDefinitionObjectId = todatetime(jd.jobDefinitionObjectId),\n                jobDurationSeconds = tolong(datetime_diff('second',todatetime(jd.jobEndTimeUtc),todatetime(jd.jobStartTimeUtc)))\n        |summarize arg_max(EventProcessedUtcTime,*) by id //deduplicate\n        |project-away jd,data\n    }\n    .create-or-alter function with (docstring ='Function called on workspaceEvents update policy to flatten/expand JSON data')\n    expandWorkspaceEvents()\n    {\n        workspaceEvents\n        | extend ed = parse_json(data)\n        | extend itemId = tostring(ed.itemId), \n                itemName = tostring(ed.itemName),\n                workspaceId = tostring(ed.workspaceId), \n                workspaceName = tostring(ed.workspaceName), \n                itemKind = tostring(ed.itemKind),\n                executingPrincipalId = tostring(ed.executingPrincipalId),\n                executingPrincipalType =  tostring(ed.executingPrincipalType)\n        | summarize arg_max(EventProcessedUtcTime,*) by id //deduplicate\n        | project-away ed, data\n    }\n    .create-or-alter function with (docstring ='Function called on storageEvents update policy to flatten/expand JSON data')\n    expandStorageEvents()\n    {\n        storageEvents\n        | extend sd = parse_json(data)\n        | extend api = tostring(sd.api),\n                clientRequestId = tostring(sd.clientRequestId),\n                requestId = tostring(sd.requestId),\n                eTag = tostring(sd.eTag),\n                blobUrl = tostring(sd.blobUrl),\n                url = tostring(sd.url),\n                sequencer = tostring(sd.sequencer)\n        | summarize arg_max(EventProcessedUtcTime,*) by id //deduplicate\n        | project-away sd, data\n    }    ",
        "title": "Functions",
        "dataSourceId": "4133f2a7-9b55-4846-89fa-b41381ea1e5d"
      },
      {
        "id": "2b1d16c4-9f2b-4dc1-b3c4-8b3190e24ec4",
        "content": ".execute database script <|\n    // .drop materialized-view dailyAggWorkspaceEvents\n    .create async ifnotexists materialized-view with (backfill =true) dailyAggWorkspaceEvents on table workspaceEventsExpanded\n    {\n        workspaceEventsExpanded\n        |summarize  eventCount= count() by bin([\"time\"],1d),\n         type,\n         itemKind,\n         itemName,\n         workspaceName,\n         executingPrincipalId,\n         executingPrincipalType\n    }\n    //.drop materialized-view dailyAggJobEvents\n    .create async ifnotexists materialized-view with (backfill =true) dailyAggJobEvents on table  jobEventsExpanded\n    {\n        jobEventsExpanded\n        |project-away id, EventProcessedUtcTime,datacontenttype,specversion,source, dataschemaversion, PartitionId, EventEnqueuedUtcTime,\n                    itemId,workspaceId,jobDefinitionObjectId\n        |extend shortType = replace_string(type,\"Microsoft.Fabric.JobEvents.\",\"\")\n        | evaluate pivot(shortType,max(jobStartTimeUtc))  \n                        : ([\"time\"]:datetime,\n                        subject:string,\n                        type:string,\n                        itemName:string,\n                        workspaceName:string,\n                        itemKind:string,\n                        executingPrincipalId:string,\n                        executingPrincipalType:string,\n                        jobInstanceId:string,\n                        jobType:string,\n                        jobInvokeType:string,\n                        jobStatus:string,\n                        jobEndTimeUtc:datetime,\n                        jobScheduleTimeUtc:datetime,\n                        jobDurationSeconds:long,\n                        ItemJobCreated:datetime,\n                        ItemJobStatusChanged:datetime,\n                        ItemJobSucceeded:datetime)\n        | summarize arg_max([\"time\"],jobStatus),\n                jobScheduleTimeUtc = max(jobScheduleTimeUtc),\n                jobCreatedTimeUtc= max(ItemJobCreated),\n                jobStartTimeUtc = max(ItemJobSucceeded),\n                jobEndTimeUtc = max(jobEndTimeUtc)\n                by subject,\n                itemName,\n                workspaceName,\n                itemKind,\n                jobType,\n                executingPrincipalId,\n                executingPrincipalType,\n                jobInvokeType,\n                jobInstanceId\n    }\n    // .drop materialized-view dailyAggStorageEvents \n    .create async ifnotexists materialized-view with (backfill =true) dailyAggStorageEvents on table storageEventsExpanded\n    {\n        storageEventsExpanded\n        | extend type = replace_string(type,\"Microsoft.Fabric.OneLake.\",\"\")\n        | summarize oneLakeCount = count() by bin([\"time\"],1d),\n            source,\n            subject,\n            type,\n            api\n    }",
        "title": "Materialized Views",
        "dataSourceId": "4133f2a7-9b55-4846-89fa-b41381ea1e5d"
      },
      {
        "id": "ba1af3c7-a6c5-4e10-ad2a-6b1afded58cb",
        "content": ".execute database script <|\n    .alter table jobEventsExpanded policy update \n    ```\n    [\n        {\n            \"IsEnabled\": true,\n            \"Source\": \"jobEvents\",\n            \"Query\": \"expandJobEvents()\",\n            \"IsTransactional\": false,\n            \"PropagateIngestionProperties\": false\n        }\n    ]\n    ```\n   .alter table workspaceEventsExpanded policy update \n    ```\n    [\n        {\n            \"IsEnabled\": true,\n            \"Source\": \"workspaceEvents\",\n            \"Query\": \"expandWorkspaceEvents()\",\n            \"IsTransactional\": false,\n            \"PropagateIngestionProperties\": false\n        }\n    ]\n    ```\n   .alter table storageEventsExpanded policy update \n    ```\n    [\n        {\n            \"IsEnabled\": true,\n            \"Source\": \"storageEvents\",\n            \"Query\": \"expandStorageEvents()\",\n            \"IsTransactional\": false,\n            \"PropagateIngestionProperties\": false\n        }\n    ]\n    ```    ",
        "title": "Update Policies",
        "dataSourceId": "4133f2a7-9b55-4846-89fa-b41381ea1e5d"
      },
      {
        "id": "69c53e08-af0a-4745-b85c-070a55b58252",
        "content": ".execute database script <|\n    .set-or-append jobEventsExpanded <|expandJobEvents|take 0 \n    .set-or-append workspaceEventsExpanded <|expandWorkspaceEvents| take 0\n    .set-or-append storageEventsExpanded <|expandStorageEvents| take 0\n\n\n\n\n",
        "title": "Tables",
        "dataSourceId": "4133f2a7-9b55-4846-89fa-b41381ea1e5d"
      }
    ]
  }
}